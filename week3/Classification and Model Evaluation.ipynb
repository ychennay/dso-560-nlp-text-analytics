{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Not Just Use A Linear Regression?\n",
    "\n",
    "### Assumptions for Linear Models:\n",
    "- Gaussian distribution of residuals (errors)\n",
    "- Y (target variable) is continuous on the prediction interval\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/binary.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Algorithmic Marketing (Katsov)\n",
    "\n",
    "### Finding A Decision Boundary\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/lr1.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log of Equal Odds \n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/lr2.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logit Link Function\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/lr3.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solving for Each Class (Binary Target)\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/lr4.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Likelihood\n",
    "![alt text](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/lr5.png \"Logo Title Text 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def sigmoid(z):\n",
    "    return 1 / (1 + np.exp(-z))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "poor = open(\"../datasets/poor_amazon_toy_reviews.txt\").readlines()\n",
    "good = open(\"../datasets/good_amazon_toy_reviews.txt\").readlines()\n",
    "\n",
    "good_reviews = list(map(lambda review: (review, 1), good))\n",
    "poor_reviews = list(map(lambda review: (review, 0), poor))\n",
    "\n",
    "all_reviews = good_reviews + poor_reviews\n",
    "all_reviews_df = pd.DataFrame(all_reviews, columns=[\"review\", \"positive\"])\n",
    "all_reviews_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer(ngram_range=(1, 1), \n",
    "                             stop_words=\"english\", \n",
    "                             max_features=1000,token_pattern='(?u)\\\\b[a-zA-Z][a-zA-Z]+\\\\b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(all_reviews_df[\"review\"])\n",
    "y = all_reviews_df[\"positive\"].values\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X)\n",
    "\n",
    "# calculate accuracy\n",
    "np.mean(y_pred == y)\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "confusion_matrix(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all_reviews is the original list of string text documents\n",
    "# wrong_predictions is an array of the indices where your prediction was not correct\n",
    "wrong_predictions = np.nonzero(y_pred != y)[0]\n",
    "\n",
    "np.take(np.array(all_reviews), wrong_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(y_pred == y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUROC (Area Under the Receiver Operator Curve)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "roc_auc_score(y, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names())\n",
    "data[\"TARGET\"] = y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_df, test_df = train_test_split(data)\n",
    "X_train = train_df.loc[:, ~train_df.columns.isin(['TARGET'])]\n",
    "X_test = test_df.loc[:, ~test_df.columns.isin(['TARGET'])]\n",
    "\n",
    "\n",
    "y_train = train_df[\"TARGET\"]\n",
    "y_test = test_df[\"TARGET\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape)\n",
    "print(y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "roc_auc_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_validate\n",
    "X = data.loc[:, ~data.columns.isin(['TARGET'])]\n",
    "cv_results = cross_validate(lr, X, y, cv=10,return_train_score=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results['test_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
