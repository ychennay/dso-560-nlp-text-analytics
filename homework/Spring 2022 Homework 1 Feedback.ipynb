{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bright-kelly",
   "metadata": {},
   "source": [
    "# Homework 1 Feedback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "empirical-composite",
   "metadata": {},
   "source": [
    "### Use Word Boundaries For Regex Patterns\n",
    "Since we are using regex to group together relevant **words** into themes, we want to make sure that our regex patterns do not match false positives. A common theme selected by students was `TIME`, or how long customers had to wait to receive their orders. A frequent pattern used was `(?:long|forever|waittime|waiting|wait|slow)`.\n",
    "\n",
    "The problem with this pattern is that is will [match the following words](regexr.com/6i9nk):\n",
    "* `await`\n",
    "* `waiter`\n",
    "* `along`\n",
    "* `belong`\n",
    "\n",
    "These are false positives that can, depending on hw frequently they appear, completely alter the final recommendations/findings. Using word boundaries, `\\b(?:long|forever|waittime|waiting|wait|slow)\\b`, will reduce the [number of false positives matched](regexr.com/6i9nt).\n",
    "\n",
    "### Count the Number of Reviews a Theme Appears In, Not the Absolute Frequency\n",
    "\n",
    "Consider a review that has the following text:\n",
    "> This store is slow, slow, slow. I can't imagine how long we have spent waiting in line trying to get our order. The worst.\n",
    "\n",
    "Now, pretend we have the regex `\\b(?:long|forever|waittime|waiting|wait|slow)\\b` and we substitute each match with `_TIME_`:\n",
    "```python\n",
    "import re\n",
    "\n",
    "review = \"This store is slow, slow, slow. I can't imagine how long we have spent waiting in line trying to get our order. The worst.\"\n",
    "TIME_PATTERN: re.Pattern = re.compile(r'\\b(?:long|forever|waittime|waiting|wait|slow)\\b')\n",
    "new_text = re.sub(TIME_PATTERN, '', review)\n",
    "```\n",
    "This will lead to `new_text` being\n",
    "```\n",
    "\"This store is _TIME_, _TIME_, _TIME_. I can't imagine how _TIME_ we have spent _TIME_ in line trying to get our order. The worst.\"\n",
    "```\n",
    "Then, if we actually perform a word count, we'll see that this review has `_TIME_` counted 5 times:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "tender-force",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    5\n",
       "1    0\n",
       "2    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "review = \"This store is slow, slow, slow. I can't imagine how long we have spent waiting in line trying to get our order. The worst.\"\n",
    "TIME_PATTERN: re.Pattern = re.compile(r'\\b(?:long|forever|waittime|waiting|wait|slow)\\b')\n",
    "new_text = re.sub(TIME_PATTERN, '_TIME_', review)\n",
    "\n",
    "reviews = pd.Series([new_text, \"another review\", \"one more review\"])\n",
    "reviews.str.count('_TIME_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "russian-twist",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.str.count('_TIME_').sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numerical-bosnia",
   "metadata": {},
   "source": [
    "This will weight the review by 5x with respect to the theme of `_TIME_`, essentially overcounting the frequency of `_TIME_`. It may make more sense in this use case to count the **number of reviews** that `_TIME_` appears in. We can do this using the `str.findall()` or `str.contains()` method for Pandas dataframe series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "studied-legislation",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [slow, slow, slow, long, waiting]\n",
       "1                                   []\n",
       "2                                   []\n",
       "dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_reviews = pd.Series([review, \"another review\", \"one more review\"])\n",
    "original_reviews.str.findall(TIME_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "norwegian-roommate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     True\n",
       "1    False\n",
       "2    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_reviews.str.contains(TIME_PATTERN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "encouraging-floor",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "original_reviews.str.contains(TIME_PATTERN).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stable-belief",
   "metadata": {},
   "source": [
    "### Reduce False Negatives By Including More Patterns\n",
    "\n",
    "Some students used very limited regex patterns - for instance, for the theme `FOOD`, some students only provided `\\b(burger)\\b`. But you should use your domain knowledge of McDonalds and reading through some of the reviews to identify that there's many more patterns you could be including: `\\b((?:ham)?burgers?|(?:mc)?muffins?|fries|hash browns?|mcflurr(?:y|ies))\\b`.\n",
    "\n",
    "Remember that the `?:` inside the parenthesis indicates that `(...)` is a non-capture group - this will become more and more important as we learn about capture groups and extracing phrases.\n",
    "\n",
    "By only including a few patterns, you are increasing the number of **false negatives** (actual matches that are not grouped properly into the appropriate theme)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hidden-montreal",
   "metadata": {},
   "source": [
    "### Use Case Flags and Quantifiers to Shorten the Complexity of the Pattern\n",
    "Some students used regex patterns like `r'\\b(?:gross|GROSS|disgusting|DISGUSTING|nasty|NASTYYY|NASTY|nastyyy)\\b'`.\n",
    "\n",
    "You can use `flags=re.IGNORECASE` to make the regex case insensitive: `re.sub(r'\\b(?:gross|disgusting|nasty|nastyyy)\\b', \"_TIME_\", flags=re.IGNORECASE)`.\n",
    "\n",
    "Then, you can also use quantifiers to reduce the expression even further:\n",
    "`re.sub(r'\\b(?:gross|disgusting|nasty{1,3})\\b', \"_TIME_\", flags=re.IGNORECASE)`.\n",
    "\n",
    "The `nasty{1,3}` will match `nasty`, `nastyy`, or `nastyyy`, but not `nastyyyy`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finite-genre",
   "metadata": {},
   "source": [
    "### Don't Repeat Your Code - Keep Things DRY\n",
    "\n",
    "There is a key principle in programming - `Keep things DRY (Don't Repeat Yourself)`. \n",
    "\n",
    "A lot of notebooks looked like this:\n",
    "```python\n",
    "atlanta = processed_reviews[processed_reviews.city == \"Atlanta\"]\n",
    "atlanta['review'].str.count('COLD').sum()\n",
    "atlanta['review'].str.count('LATE').sum()\n",
    "atlanta['review'].str.count('SERVICE').sum()\n",
    "\n",
    "vegas = processed_reviews[processed_reviews.city == \"Las Vegas\"]\n",
    "vegas['review'].str.count('COLD').sum()\n",
    "vegas['review'].str.count('LATE').sum()\n",
    "vegas['review'].str.count('SERVICE').sum()\n",
    "...\n",
    "```\n",
    "Refactor this into a function:\n",
    "```python\n",
    "import pandas as pd\n",
    "def count_themes(reviews: pd.DataFrame, themes: List[str], by_city: bool) -> None:\n",
    "    \"\"\"\n",
    "    Prints out the number of times. When by_city = True, then it groups by the \"city\" column. \n",
    "    If by_city = false, then it will simply sum each of the columns in the themes argument.\n",
    "    \n",
    "    reviews: The dataframe with processed reviews. It should have a column for \"city\".\n",
    "    themes: A list of column names that correspond to the themes we want to analyze.\n",
    "    \"\"\"\n",
    "    if by_city:\n",
    "        counts = reviews.groupby(\"city\")[themes].sum()\n",
    "        print(\"Themes by city:\")\n",
    "        print(counts)\n",
    "    else:\n",
    "        print(\"Theme counts:\\n\", reviews[themes].sum(axis=1)\n",
    "```\n",
    "This is not just a stylistic preference. We often have to make modifications to the data processing logic/behavior. If we repeat the same lines of code over and over again, we have to make changes in multiple different places, instead of only one central source of truth.\n",
    "\n",
    "### Provide Specific, Actionable Insights - Go One Level Deeper\n",
    "\n",
    "Some insights and recommendations were too generic. For example,\n",
    "> We saw that customer service was the top issue in most cities, specifically Las Vegas and Chicago, where X% of reviews mentioned customer service. We recommend improving employee training and emphasizing better staff responses to customers to improve quality.\n",
    "\n",
    "This is not specific enough to be actionable for management. Managers will generally always be trying to improve customer service. After you've identified that customer service is a trouble area, you need to do the following:\n",
    "\n",
    "1. Filter for the reviews mentioning the customer service theme.\n",
    "2. Identify any recurring patterns or topics within these specific reviews. Do they mention a specific type of order being repeatedly messed up? Are they frequently referencing rudeness in the way that staff respond to customers? Are staff constantly forgetting different line items in an order?\n",
    "3. From there, identify specific action items that an operations-level manager (ie. a regional manager) could try to implement:\n",
    "* Add an extra module in new employee onboarding to de-escalate tense situations and common phrases to use when talking to difficult staff to maintain professionalism.\n",
    "* Implement an operational change that orders must be cross-checked by two staff members before being served to a customer to reduce the number of incorrect/forgotten order items.\n",
    "\n",
    "In general, go **one level deeper in your recommendations** (if you find customer service is the issue, then dig deeper and identify the sub-themes within customer service - that is the level of recommendations you should be making to management). Making insights that are too generic/high-level reduces the effectiveness of the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "frequent-appeal",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
