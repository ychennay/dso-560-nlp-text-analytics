{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction\n",
    "\n",
    "## The Problem\n",
    "\n",
    "There is an interesting tradeoff between model performance and a feature's dimensionality:\n",
    "![http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/dimensionality_vs_performance.png)\n",
    "\n",
    ">*If the amount of available training data is fixed, then overfitting occurs if we keep adding dimensions. On the other hand, if we keep adding dimensions, the amount of **training data needs to grow exponentially fast to maintain the same coverage** and to avoid overfitting* ([Computer Vision for Dummies](http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/)).\n",
    "\n",
    "![http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/](https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/curseofdimensionality.png)\n",
    "\n",
    "### Multi-Collinearity\n",
    "\n",
    "In many cases, there is a high degree of correlation between many of the features in a dataset. For instance, suppose that you\n",
    "\n",
    "\n",
    "## Sparsity\n",
    "\n",
    "- High dimensionality increases the sparsity of your features (**what NLP techniques have we used that illustrate this point?**)\n",
    "- The density of the training samples decreases when dimensionality increases:\n",
    "- Distance measures (Euclidean, for instance) start losing their effectiveness, because there isn't much difference between the max and min distances in higher dimensions.\n",
    "- Many models that rely upon assumptions of Gaussian distributions (like OLS linear regression), Gaussian mixture models, Gaussian processes, etc. become less and less effective since their distributions become flatter and \"fatter tailed\".\n",
    "![http://www.visiondummy.com/2014/04/curse-dimensionality-affect-classification/](images/distance-asymptote.png)\n",
    "\n",
    "What is the amount of data needed to maintain **20% coverage** of the feature space? For 1 dimension, it is **20% of the entire population's dataset**. For a dimensionality of $D$:\n",
    "\n",
    "$$\n",
    "X^{D} = .20\n",
    "$$\n",
    "$$\n",
    "(X^{D})^{\\frac{1}{D}} = .20^{\\frac{1}{D}}\n",
    "$$\n",
    "$$\n",
    "X = \\sqrt[D]{.20}\n",
    "$$\n",
    "You can approximate this as \n",
    "```python\n",
    "def coverage_requirement(requirement, D):\n",
    "    return requirement ** (1 / D)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "for d in range(1,20):\n",
    "    y.append(coverage_requirement(0.10, d))\n",
    "    x.append(d)\n",
    "    \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.xlabel(\"Number of Dimensions\")\n",
    "plt.ylabel(\"Appromximate % of Population Dataset\")\n",
    "plt.title(\"% of Dataset Needed to Maintain 10% Coverage of Feature Space\")\n",
    "plt.show()\n",
    "```\n",
    "<img src=\"images/coverage-needed.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>across the street</th>\n",
       "      <th>and it was</th>\n",
       "      <th>and the food</th>\n",
       "      <th>at the drive</th>\n",
       "      <th>at the window</th>\n",
       "      <th>at this location</th>\n",
       "      <th>back to the</th>\n",
       "      <th>because of the</th>\n",
       "      <th>been to this</th>\n",
       "      <th>behind the counter</th>\n",
       "      <th>...</th>\n",
       "      <th>to this mcdonalds</th>\n",
       "      <th>up my order</th>\n",
       "      <th>up to the</th>\n",
       "      <th>ve been to</th>\n",
       "      <th>ve ever been</th>\n",
       "      <th>vegas this is</th>\n",
       "      <th>went through the</th>\n",
       "      <th>went to the</th>\n",
       "      <th>you have to</th>\n",
       "      <th>you want to</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows × 101 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      across the street  and it was  and the food  at the drive  \\\n",
       "0                     0           0             0             0   \n",
       "1                     0           0             0             0   \n",
       "2                     0           0             0             0   \n",
       "3                     0           0             0             0   \n",
       "4                     0           0             0             0   \n",
       "...                 ...         ...           ...           ...   \n",
       "1521                  0           0             0             0   \n",
       "1522                  0           0             0             0   \n",
       "1523                  0           0             0             0   \n",
       "1524                  0           0             0             0   \n",
       "1525                  1           0             0             0   \n",
       "\n",
       "      at the window  at this location  back to the  because of the  \\\n",
       "0                 0                 0            0               0   \n",
       "1                 0                 0            0               0   \n",
       "2                 1                 0            0               0   \n",
       "3                 0                 0            0               0   \n",
       "4                 0                 0            0               0   \n",
       "...             ...               ...          ...             ...   \n",
       "1521              0                 0            0               0   \n",
       "1522              0                 0            0               0   \n",
       "1523              0                 0            0               0   \n",
       "1524              0                 0            0               0   \n",
       "1525              0                 0            0               0   \n",
       "\n",
       "      been to this  behind the counter  ...  to this mcdonalds  up my order  \\\n",
       "0                0                   0  ...                  0            0   \n",
       "1                0                   0  ...                  0            0   \n",
       "2                0                   0  ...                  0            0   \n",
       "3                0                   0  ...                  0            0   \n",
       "4                0                   0  ...                  0            0   \n",
       "...            ...                 ...  ...                ...          ...   \n",
       "1521             0                   0  ...                  0            0   \n",
       "1522             0                   0  ...                  0            0   \n",
       "1523             0                   0  ...                  0            0   \n",
       "1524             0                   0  ...                  0            0   \n",
       "1525             0                   0  ...                  0            0   \n",
       "\n",
       "      up to the  ve been to  ve ever been  vegas this is  went through the  \\\n",
       "0             0           0             0              0                 0   \n",
       "1             0           1             1              0                 0   \n",
       "2             0           0             0              0                 0   \n",
       "3             0           0             0              0                 0   \n",
       "4             0           0             0              0                 0   \n",
       "...         ...         ...           ...            ...               ...   \n",
       "1521          0           0             0              0                 0   \n",
       "1522          0           0             0              0                 0   \n",
       "1523          0           0             0              0                 0   \n",
       "1524          0           0             0              0                 0   \n",
       "1525          0           0             0              0                 0   \n",
       "\n",
       "      went to the  you have to  you want to  \n",
       "0               0            0            0  \n",
       "1               0            0            0  \n",
       "2               0            0            0  \n",
       "3               0            0            0  \n",
       "4               0            0            0  \n",
       "...           ...          ...          ...  \n",
       "1521            0            0            0  \n",
       "1522            0            0            0  \n",
       "1523            0            0            0  \n",
       "1524            0            0            0  \n",
       "1525            0            0            0  \n",
       "\n",
       "[1526 rows x 101 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#reviews = pd.read_csv(\"mcdonalds-yelp-negative-reviews.csv\", encoding='latin-1')\n",
    "reviews = open(\"mcdonalds-yelp-negative-reviews.csv\", encoding='latin-1')\n",
    "\n",
    "#text = reviews[\"review\"].values\n",
    "text = reviews.readlines()\n",
    "\n",
    "\n",
    "vectorizer = CountVectorizer(ngram_range=(3,3), min_df=0.01, max_df=0.75, max_features=200)\n",
    "# tokenize and build vocab\n",
    "vectorizer.fit(text)\n",
    "vector = vectorizer.transform(text)\n",
    "features = vector.toarray()\n",
    "features_df = pd.DataFrame(features, columns=vectorizer.get_feature_names())\n",
    "features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I love to eat McDonalds\n",
    "\n",
    "[I love to] [eat McDonalds END]\n",
    "[I love to] [love to eat] [to eat McDonalds]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tri-Gram 1</th>\n",
       "      <th>Tri-Gram 2</th>\n",
       "      <th>Correlation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1848</th>\n",
       "      <td>front of me</td>\n",
       "      <td>in front of</td>\n",
       "      <td>0.782169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3048</th>\n",
       "      <td>in front of</td>\n",
       "      <td>front of me</td>\n",
       "      <td>0.782169</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8581</th>\n",
       "      <td>through the drive</td>\n",
       "      <td>went through the</td>\n",
       "      <td>0.761323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9881</th>\n",
       "      <td>went through the</td>\n",
       "      <td>through the drive</td>\n",
       "      <td>0.761323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4798</th>\n",
       "      <td>my way to</td>\n",
       "      <td>on my way</td>\n",
       "      <td>0.740935</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Tri-Gram 1         Tri-Gram 2  Correlation\n",
       "1848        front of me        in front of     0.782169\n",
       "3048        in front of        front of me     0.782169\n",
       "8581  through the drive   went through the     0.761323\n",
       "9881   went through the  through the drive     0.761323\n",
       "4798          my way to          on my way     0.740935"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "correlations = features_df.corr()\n",
    "correlations_stacked = correlations.stack().reset_index()\n",
    "#set column names\n",
    "correlations_stacked.columns = ['Tri-Gram 1','Tri-Gram 2','Correlation']\n",
    "correlations_stacked = correlations_stacked[correlations_stacked[\"Correlation\"] < 1]\n",
    "correlations_stacked = correlations_stacked.sort_values(by=['Correlation'], ascending=False)\n",
    "correlations_stacked.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in /Users/yuchen/miniconda3/lib/python3.8/site-packages (0.11.1)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from seaborn) (3.3.4)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from seaborn) (1.6.1)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from seaborn) (1.2.2)\n",
      "Requirement already satisfied: numpy>=1.15 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from seaborn) (1.20.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from matplotlib>=2.2->seaborn) (8.1.2)\n",
      "Requirement already satisfied: six in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.15.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in /Users/yuchen/miniconda3/lib/python3.8/site-packages (from pandas>=0.23->seaborn) (2021.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'correlations' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-73dd2cb42ffe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"figure.figsize\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheatmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorrelations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'correlations' is not defined"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.figsize\"] = (15,15)\n",
    "sns.heatmap(correlations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principle Component Analysis\n",
    "\n",
    "If you have an original matrix $Z$, you can decompose this matrix into two smaller matrices $X$ and $Q$. \n",
    "\n",
    "## Important Points:\n",
    "\n",
    "- Multiplying a vector by a matrix typically changes the direction of the vector. For instance:\n",
    "<figure>\n",
    "  <img src=\"https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/multvector.png\" alt=\"my alt text\"/>\n",
    "    <figcaption><a href=\"https://lazyprogrammer.me/tutorial-principal-components-analysis-pca\">Lazy Programmer- \n",
    "        Tutorial to PCA</a></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original = [\n",
    "    [1, 2, 0, 1],\n",
    "    [0, 2, 1, 0]\n",
    "]\n",
    "\n",
    "D = 4\n",
    "N = 2\n",
    "\n",
    "eigenvalues = [0.4, 0.2, 0.5, 0.1]\n",
    "\n",
    "Goal: keep 80% of the original data's signal\n",
    "\n",
    "[0.5, 0.4, 0.05, 0.05, 0.00, 0.000]    \n",
    "\n",
    "eigenvectors = [\n",
    "    \n",
    "    [-2, 1, 0.4, 1.5],\n",
    "    [-4, -1, 2, 2.0]\n",
    "]\n",
    "\n",
    "original = [\n",
    "    [1, 2, 0, 1],\n",
    "    [0, 2, 1, 0]\n",
    "]\n",
    "\n",
    "(2 x 4)\n",
    "\n",
    "reduced_dimensions = [\n",
    "    [0.4, -2],\n",
    "    [2, -4]\n",
    "]\n",
    "\n",
    "(2 x 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "D = original number of dimensions\n",
    "N = # of rows in dataset\n",
    "original dataset = N x D\n",
    ":\n",
    "    PCA(...) ->>>>\n",
    "    - D eigenvectors, each N elements long\n",
    "    - D eigenvalues -> [0.23, 0.44, 0.0002, 0.10, 0.05]\n",
    "    \n",
    "K = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, there are eigenvalues λ and eigenvectors $v$ such that\n",
    "\n",
    "$$\n",
    "\\sum{X}v = \\lambda v\n",
    "$$\n",
    "\n",
    "Multiplying the eigenvectors $v$ with the eigenvalue $\\lambda$ does not change the direction of the eigenvector.\n",
    "\n",
    "Multiplying the eigenvector $v$ by the covariance matrix $\\sum{X}$ also does not change the direction of the eigenvector.\n",
    "\n",
    "If our data $X$ is of shape $N \\times D$, it turns out that we have $D$ eigenvalues and $D$ eigenvectors. This means we can arrange the eigenvalues $\\lambda$ in decreasing order so that\n",
    "\n",
    "$$\n",
    "\\lambda_3 > \\lambda_2 > \\lambda_5\n",
    "$$\n",
    "\n",
    "In this case, $\\lambda_3$ is the largest eigenvalue, followed by $\\lambda_2$, and then $\\lambda_5$. Then, we can arrange \n",
    "\n",
    "We can also rearrange the eigenvectors the same: $v_3$ will be the first column, $v_2$ will be the second column, and $v_5$ will be the third column.\n",
    "\n",
    "We'll end up with two matrices $V$ and $\\Lambda$:\n",
    "<figure>\n",
    "  <img src=\"https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/pca1.png\" alt=\"my alt text\"/>\n",
    "    <figcaption><a href=\"https://lazyprogrammer.me/tutorial-principal-components-analysis-pca\">Lazy Programmer- \n",
    "        Tutorial to PCA</a></figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1526, 101)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# what is the shape of our features?\n",
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# features -> age, gpa, final_score, is_female, is_full_time\n",
    "\n",
    "a = [45, 3.4, 0, 1]\n",
    "b = [21, 3.5, 1, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22699846, -0.08991974, -0.01202515, -0.10444492],\n",
       "       [-0.19585318, -0.07052395, -0.07381868,  0.1699686 ],\n",
       "       [-0.14766952,  0.73481296, -0.38769515, -0.20654003],\n",
       "       ...,\n",
       "       [-0.20875385, -0.0046716 , -0.08673423, -0.10876011],\n",
       "       [-0.19224779, -0.03921425,  0.0785265 ,  0.01478717],\n",
       "       [-0.22641542, -0.09132363, -0.02443358, -0.06312254]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=4)\n",
    "\n",
    "Z = pca.fit_transform(features)\n",
    "\n",
    "# what is the shape of Z?\n",
    "Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# what will happen if we take the correlation matrix and covariance matrix of our new reduced features?\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "covariances = pd.DataFrame(np.cov(Z.transpose()))\n",
    "plt.rcParams[\"figure.figsize\"] = (5,5)\n",
    "sns.heatmap(covariances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.22699852, -0.08987271],\n",
       "       [-0.19585331, -0.07030853],\n",
       "       [-0.1476693 ,  0.73489121],\n",
       "       ...,\n",
       "       [-0.2087537 , -0.00495443],\n",
       "       [-0.19224662, -0.04005471],\n",
       "       [-0.22641544, -0.09128096]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA(n_components=2)\n",
    "Z_two_dimensions = pca.fit_transform(features)\n",
    "Z_two_dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.scatter(Z_two_dimensions[:,0], Z_two_dimensions[:, 1])\n",
    "reduced_features_df = pd.DataFrame(Z_two_dimensions, columns=[\"x1\", \"x2\"])\n",
    "reduced_features_df[\"text\"] = text\n",
    "reduced_features_df.to_csv(\"reduced_features.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Singular Value Decomposition\n",
    "\n",
    "Given an input matrix $A$, we want to try to represent it instead as three smaller matrices $U$, $\\sum$, and $V$. Instead of **$n$ original terms**, we want to represent each document as **$r$ concepts** (other referred to as **latent dimensions**, or **latent factors**):\n",
    "<figure>\n",
    "  <img src=\"https://raw.githubusercontent.com/ychennay/dso-560-nlp-text-analytics/main/images/svd.png\" alt=\"my alt text\"/>\n",
    "    <figcaption><i>\n",
    "        <a href=\"https://www.youtube.com/watch?v=P5mlg91as1c\">Mining of Massive Datasets - Dimensionality Reduction: Singular Value Decomposition</a> by Leskovec, Rajaraman, and Ullman (Stanford University)</i></figcaption>\n",
    "</figure>\n",
    "\n",
    "Here, **$A$ is your matrix of word vectors** - you could use any of the word vectorization techniques we have learned so far, include one-hot encoding, word count, TF-IDF.\n",
    "\n",
    "- $\\sum$ will be a **diagonal matrix** with values that are positive and sorted in decreasing order. Its value indicate the **variance (information encoded on that new dimension)**- therefore, the higher the value, the stronger that dimension is in capturing data from A, the original features. For our purposes, we can think of the rank of this $\\sum$ matrix as the number of desired dimensions. Instance, if we want to reduce $A$ from shape $1020 x 300$ to $1020 x 10$, we will want to reduce the rank of $\\sum$ from 300 to 10.\n",
    "\n",
    "- $U^T U = I$ and $V^T V = I$\n",
    "\n",
    "## Measuring the Quality of the Reconstruction\n",
    "\n",
    "A popular metric used for measuring the quality of the reconstruction is the [Frobenius Norm](https://en.wikipedia.org/wiki/Matrix_norm#Frobenius_norm). When you explain your methodology for reducing dimensions, usually managers / stakeholders will want to some way to compare multiple dimensionality techniques' ability to quantify its ability to retain information but trim dimensions:\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "||A_{old}-A_{new}||_{F} = \\sqrt{\\sum_{ij}{(A^{old}_{ij}- A^{new}_{ij}}})^2\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "## Heuristic Step for How Many Dimensions to Keep\n",
    "\n",
    "1. Sum the $\\sum$ matrix's diagonal values: \n",
    "$$\n",
    "\\begin{equation}\n",
    "\\sum_{i}^{m}\\sigma_{i}\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "2. Define your threshold of \"information\" (variance) $\\alpha$ to keep: usually 80% to 90%. \n",
    "\n",
    "3. Define your cutoff point $C$: $$\n",
    "\\begin{equation}\n",
    "C = \\sum_{i}^{m}\\sigma_{i} \\alpha\n",
    "\\end{equation}\n",
    "$$\n",
    "\n",
    "4. Beginning with your largest singular value, sum your singular values $\\sigma_{i}$ until it is greater than C. Retain only those dimensions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.linalg import svd\n",
    "x = np.linspace(1,20, 20) # create the first dimension\n",
    "x = np.concatenate((x,x))\n",
    "y = x + np.random.normal(0,1, 40) # create the second dimension\n",
    "z = x + np.random.normal(0,2, 40) # create the third dimension\n",
    "a = x + np.random.normal(0,4, 40) # create the fourth dimension\n",
    "plt.scatter(x,y) # plot just the first two dimensions\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        , -0.82661129, -1.20240144, -1.71343991],\n",
       "       [ 2.        ,  3.14375759,  4.69355119,  4.43233514],\n",
       "       [ 3.        ,  2.4086857 ,  2.16680283,  7.62687492],\n",
       "       [ 4.        ,  4.33746394,  5.49123683,  0.95831808],\n",
       "       [ 5.        ,  3.00077306,  6.44323028,  7.66546629],\n",
       "       [ 6.        ,  7.20045771,  5.81521277,  0.88809719],\n",
       "       [ 7.        ,  6.64750276,  7.57898262,  6.84247986],\n",
       "       [ 8.        ,  7.38055783,  7.4819841 ,  6.47746044],\n",
       "       [ 9.        ,  9.23912669, 10.02780899,  1.42548363],\n",
       "       [10.        ,  8.81059739,  9.63079304,  5.70318617],\n",
       "       [11.        , 11.06173356, 14.35070992,  8.39095803],\n",
       "       [12.        , 10.77148832, 12.98019819, 15.18818223],\n",
       "       [13.        , 12.23744741, 13.55690515,  3.43976111],\n",
       "       [14.        , 12.98078911, 17.11257907, 15.89215173],\n",
       "       [15.        , 13.46312576, 17.34618259, 19.95921117],\n",
       "       [16.        , 16.01171393, 17.67611252,  7.6921914 ],\n",
       "       [17.        , 16.705963  , 13.23857386, 21.73117167],\n",
       "       [18.        , 19.64154166, 16.79783139, 17.85498404],\n",
       "       [19.        , 17.41296781, 17.796067  , 21.54790899],\n",
       "       [20.        , 20.13769666, 18.72052127, 16.71695352],\n",
       "       [ 1.        ,  2.41578229,  3.91292321,  3.32522557],\n",
       "       [ 2.        ,  1.76457355, -2.55465832,  4.05164312],\n",
       "       [ 3.        ,  1.91304394,  3.09921015,  6.95760017],\n",
       "       [ 4.        ,  4.64759262,  3.84001359, -2.52823818],\n",
       "       [ 5.        ,  5.10831812,  4.89544967,  0.5083831 ],\n",
       "       [ 6.        ,  5.97485137,  3.44627394,  4.24580029],\n",
       "       [ 7.        ,  7.11937779,  6.96096493, 13.23435383],\n",
       "       [ 8.        ,  9.31459433,  6.05112026,  7.96322468],\n",
       "       [ 9.        ,  8.77426568,  6.27910469,  6.29493245],\n",
       "       [10.        , 11.23917253,  8.7955014 ,  2.54945442],\n",
       "       [11.        , 11.85518844, 13.35655984, 10.19953726],\n",
       "       [12.        , 10.98824584, 14.56514301, 12.98853206],\n",
       "       [13.        , 11.82983948, 12.06020364, 17.01488939],\n",
       "       [14.        , 14.27913492,  9.86017119, 15.91304701],\n",
       "       [15.        , 15.21492882, 16.22712388, 21.34748464],\n",
       "       [16.        , 15.38503604, 16.01969026, 19.86003748],\n",
       "       [17.        , 15.96304809, 18.3101284 , 12.26507947],\n",
       "       [18.        , 18.28285007, 19.89910095, 18.07530834],\n",
       "       [19.        , 18.14083781, 17.49050972, 22.45820039],\n",
       "       [20.        , 20.96371008, 18.63605716, 18.59974073]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "A = np.stack([x,y,z,a]).T\n",
    "A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "s is [150.61840432  23.93763666  10.55318245   3.81974409] ((4,))\n",
      "\n",
      "U is [[ 0.00912584  0.04363913 -0.08835298 ... -0.15604797 -0.23793002\n",
      "  -0.19440563]\n",
      " [-0.04742135 -0.03375326  0.15423831 ... -0.21921188 -0.0173763\n",
      "  -0.28669429]\n",
      " [-0.05062429 -0.18430814 -0.01640971 ...  0.17314973 -0.08508066\n",
      "  -0.09459875]\n",
      " ...\n",
      " [-0.24651081  0.035965    0.1107751  ...  0.89734879 -0.05966394\n",
      "  -0.06781198]\n",
      " [-0.25602846 -0.14818377 -0.07483395 ... -0.03950742  0.91264761\n",
      "  -0.05128918]\n",
      " [-0.25947754  0.05186514 -0.17494206 ... -0.07705335 -0.07298676\n",
      "   0.86972067]] ((40, 40))\n",
      "\n",
      "V is [[-0.50077866 -0.49266149 -0.50189005 -0.5045907 ]\n",
      " [ 0.229212    0.30029712  0.34169151 -0.86054077]\n",
      " [-0.33057393 -0.51507876  0.78951053  0.04569321]\n",
      " [ 0.76642252 -0.63387709 -0.08959029 -0.05263024]] ((4, 4))\n"
     ]
    }
   ],
   "source": [
    "D = 1\n",
    "U, s, V = svd(A)\n",
    "print(f\"s is {s} ({s.shape})\\n\")\n",
    "print(f\"U is {U} ({U.shape})\\n\")\n",
    "print(f\"V is {V} ({V.shape})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  1.37452005,   0.        ,   0.        ,   0.        ],\n",
       "       [ -7.14252732,   0.        ,   0.        ,   0.        ],\n",
       "       [ -7.62494958,   0.        ,   0.        ,   0.        ],\n",
       "       [ -7.37957158,   0.        ,   0.        ,   0.        ],\n",
       "       [-11.08397476,   0.        ,   0.        ,   0.        ],\n",
       "       [ -9.91878315,   0.        ,   0.        ,   0.        ],\n",
       "       [-14.03688686,   0.        ,   0.        ,   0.        ],\n",
       "       [-14.66594552,   0.        ,   0.        ,   0.        ],\n",
       "       [-14.81091314,   0.        ,   0.        ,   0.        ],\n",
       "       [-17.05980248,   0.        ,   0.        ,   0.        ],\n",
       "       [-22.39473322,   0.        ,   0.        ,   0.        ],\n",
       "       [-25.49448914,   0.        ,   0.        ,   0.        ],\n",
       "       [-21.07878884,   0.        ,   0.        ,   0.        ],\n",
       "       [-30.01370117,   0.        ,   0.        ,   0.        ],\n",
       "       [-32.92155217,   0.        ,   0.        ,   0.        ],\n",
       "       [-28.65368653,   0.        ,   0.        ,   0.        ],\n",
       "       [-34.35327736,   0.        ,   0.        ,   0.        ],\n",
       "       [-36.13077027,   0.        ,   0.        ,   0.        ],\n",
       "       [-37.89803652,   0.        ,   0.        ,   0.        ],\n",
       "       [-37.76750334,   0.        ,   0.        ,   0.        ],\n",
       "       [ -5.33267666,   0.        ,   0.        ,   0.        ],\n",
       "       [ -2.6331586 ,   0.        ,   0.        ,   0.        ],\n",
       "       [ -7.51102211,   0.        ,   0.        ,   0.        ],\n",
       "       [ -4.94434366,   0.        ,   0.        ,   0.        ],\n",
       "       [ -7.73406775,   0.        ,   0.        ,   0.        ],\n",
       "       [ -9.82029305,   0.        ,   0.        ,   0.        ],\n",
       "       [-17.18446474,   0.        ,   0.        ,   0.        ],\n",
       "       [-15.65033732,   0.        ,   0.        ,   0.        ],\n",
       "       [-15.15753523,   0.        ,   0.        ,   0.        ],\n",
       "       [-16.24569966,   0.        ,   0.        ,   0.        ],\n",
       "       [-23.19927611,   0.        ,   0.        ,   0.        ],\n",
       "       [-25.28682223,   0.        ,   0.        ,   0.        ],\n",
       "       [-26.97668   ,   0.        ,   0.        ,   0.        ],\n",
       "       [-27.02397838,   0.        ,   0.        ,   0.        ],\n",
       "       [-33.92346353,   0.        ,   0.        ,   0.        ],\n",
       "       [-33.65338659,   0.        ,   0.        ,   0.        ],\n",
       "       [-31.75613246,   0.        ,   0.        ,   0.        ],\n",
       "       [-37.12906517,   0.        ,   0.        ,   0.        ],\n",
       "       [-38.56259845,   0.        ,   0.        ,   0.        ],\n",
       "       [-39.08209357,   0.        ,   0.        ,   0.        ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[D:] = 0\n",
    "S = np.zeros((A.shape[0], A.shape[1]))\n",
    "S[:A.shape[1], :A.shape[1]] = np.diag(s)\n",
    "A_reconstructed = U.dot(S.dot(V))\n",
    "np.sum((A_reconstructed - A) ** 2) ** (1/2) # Frobenius norm\n",
    "# reconstruct matrix\n",
    "U.dot(S)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Toy Example of SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a matrix\n",
    "B = np.array([[1, 2], [3, 4], [5, 6]])\n",
    "print(\"B:\\n\", B)\n",
    "# Singular-value decomposition\n",
    "U, s, VT = svd(B)\n",
    "# create m x n Sigma matrix\n",
    "Sigma = np.zeros((B.shape[0],B.shape[1]))\n",
    "# populate Sigma with n x n diagonal matrix\n",
    "Sigma[:B.shape[1], :B.shape[1]] = np.diag(s)\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scikit Learn Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "       [ 0.07792301,  0.12682275,  0.03451552,  0.27582093,  0.0317126 ],\n",
       "       [ 0.16065739,  0.73488305,  0.45956057, -0.28927067, -0.06417606],\n",
       "       ...,\n",
       "       [ 0.0413113 ,  0.10338238,  0.07625642,  0.01606151, -0.03383459],\n",
       "       [ 0.09679285,  0.18280023, -0.11305105,  0.21265781, -0.12673046],\n",
       "       [ 0.02225171,  0.04062618,  0.00294204,  0.06950387, -0.00181659]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=5)\n",
    "reduced_svd_features = svd.fit_transform(features)\n",
    "reduced_svd_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([22.85188153, 12.60754141, 11.23969981, 10.78678616,  9.82741657])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.singular_values_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5890253600313473"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svd.explained_variance_.sum()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
